{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from scipy.misc import imread\n",
    "from sklearn import svm, mixture\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wczytanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_valid_image_name(image_name):\n",
    "    return re.match(r'^[iopz]_\\d+\\.jpg$', image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"Dane\"\n",
    "wrong_filenames_path = \"wrong_filenames.txt\"\n",
    "wrong_sizes_path = \"wrong_sizes.txt\"\n",
    "with open(wrong_filenames_path, \"w\") as wrong_filenames:\n",
    "    with open(wrong_sizes_path, \"w\") as wrong_sizes:\n",
    "        languages = [f for f in listdir(data_path)]\n",
    "        data = []\n",
    "        for language in languages:\n",
    "            language_path = join(data_path, language)\n",
    "            image_names = [f for f in listdir(language_path) if isfile(join(language_path, f))]\n",
    "            for image_name in image_names:\n",
    "                image_path = join(language_path, image_name)\n",
    "                if is_valid_image_name(image_name):\n",
    "                    image = imread(image_path)\n",
    "                    image_shape = image.shape[:2]\n",
    "                    if image_shape != (15, 15):\n",
    "                        wrong_sizes.write(image_path + \"\\n\")\n",
    "                        continue\n",
    "                    letter, index = image_name.split(\"_\")\n",
    "                    index = index.split(\".\")[0]\n",
    "                    data.append([language, letter, index, image])\n",
    "                else:\n",
    "                    wrong_filenames.write(image_path + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: 856\n"
     ]
    }
   ],
   "source": [
    "rows_cnt = len(data)\n",
    "print(\"Data size: {}\".format(rows_cnt))\n",
    "data = np.array(data, dtype = \"object\")\n",
    "# data = np.array([np.array(row, dtype = \"object\") for row in data])\n",
    "data = pd.DataFrame(data=data, columns = [\"Language\", \"Letter\", \"Index\", \"Image\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Language Letter Index                                              Image\n",
      "0    ormiański      o     4  [[253, 254, 252, 254, 254, 254, 254, 255, 255,...\n",
      "1    ormiański      p    22  [[255, 253, 252, 255, 254, 242, 227, 252, 253,...\n",
      "2    ormiański      z    25  [[254, 253, 253, 254, 255, 249, 255, 249, 255,...\n",
      "3    ormiański      z     8  [[245, 246, 250, 146, 36, 38, 104, 224, 225, 1...\n",
      "4    ormiański      o    13  [[255, 254, 248, 255, 252, 249, 253, 254, 252,...\n",
      "5    ormiański      p    26  [[255, 246, 255, 251, 255, 251, 253, 250, 255,...\n",
      "6    ormiański      z    20  [[253, 255, 252, 249, 255, 255, 249, 255, 255,...\n",
      "7    ormiański      p    20  [[252, 255, 251, 255, 252, 251, 255, 254, 253,...\n",
      "8    ormiański      z    15  [[253, 255, 250, 249, 70, 69, 144, 152, 149, 2...\n",
      "9    ormiański      z     1  [[244, 248, 250, 104, 36, 45, 38, 204, 61, 54,...\n",
      "10   ormiański      i     4  [[255, 255, 254, 251, 126, 139, 248, 255, 255,...\n",
      "11   ormiański      i     1  [[249, 248, 250, 245, 245, 245, 251, 248, 249,...\n",
      "12   ormiański      i    12  [[253, 251, 31, 160, 253, 255, 255, 255, 254, ...\n",
      "13   ormiański      i     2  [[251, 253, 243, 251, 250, 247, 255, 248, 251,...\n",
      "14   ormiański      i    17  [[255, 255, 197, 198, 168, 172, 251, 254, 251,...\n",
      "15   ormiański      p     9  [[255, 249, 255, 247, 255, 255, 254, 110, 97, ...\n",
      "16   ormiański      z    24  [[252, 255, 255, 251, 255, 252, 248, 255, 255,...\n",
      "17   ormiański      o    22  [[255, 249, 255, 254, 252, 253, 255, 251, 253,...\n",
      "18   ormiański      i     9  [[255, 246, 253, 54, 205, 208, 255, 251, 255, ...\n",
      "19   ormiański      o    14  [[248, 254, 243, 24, 28, 13, 19, 18, 25, 29, 3...\n",
      "20   ormiański      z    14  [[239, 21, 30, 37, 17, 59, 103, 34, 40, 32, 57...\n",
      "21   ormiański      i     6  [[255, 255, 250, 249, 250, 251, 247, 255, 250,...\n",
      "22   ormiański      i    15  [[254, 84, 94, 0, 245, 246, 250, 255, 251, 255...\n",
      "23   ormiański      z     9  [[253, 255, 253, 255, 251, 254, 253, 202, 128,...\n",
      "24   ormiański      o     9  [[255, 250, 255, 255, 250, 246, 188, 244, 244,...\n",
      "25   ormiański      z    10  [[250, 243, 245, 245, 101, 60, 65, 103, 236, 2...\n",
      "26   ormiański      p    12  [[255, 250, 255, 252, 254, 255, 246, 255, 246,...\n",
      "27   ormiański      i    18  [[254, 253, 253, 254, 255, 252, 255, 251, 255,...\n",
      "28   ormiański      o     8  [[255, 252, 250, 237, 155, 82, 12, 31, 38, 15,...\n",
      "29   ormiański      i     5  [[253, 253, 252, 254, 252, 246, 251, 255, 255,...\n",
      "..         ...    ...   ...                                                ...\n",
      "826     grecki      z    22  [[255, 254, 249, 253, 182, 219, 238, 245, 242,...\n",
      "827     grecki      o     7  [[255, 250, 253, 255, 247, 253, 254, 35, 31, 7...\n",
      "828     grecki      o    25  [[255, 251, 253, 253, 238, 255, 253, 255, 255,...\n",
      "829     grecki      p    13  [[165, 45, 40, 39, 46, 48, 49, 45, 49, 40, 49,...\n",
      "830     grecki      o    10  [[254, 254, 253, 255, 133, 52, 55, 47, 61, 58,...\n",
      "831     grecki      i    23  [[252, 255, 250, 250, 255, 247, 66, 213, 255, ...\n",
      "832     grecki      z    13  [[255, 224, 142, 145, 137, 149, 152, 132, 159,...\n",
      "833     grecki      z    19  [[255, 251, 255, 254, 255, 250, 253, 255, 255,...\n",
      "834     grecki      p     5  [[253, 252, 255, 251, 251, 253, 255, 252, 250,...\n",
      "835     grecki      i    24  [[255, 255, 254, 254, 251, 254, 255, 231, 252,...\n",
      "836     grecki      z    12  [[227, 28, 28, 19, 23, 25, 25, 30, 32, 41, 34,...\n",
      "837     grecki      i     7  [[255, 249, 251, 255, 255, 163, 218, 252, 255,...\n",
      "838     grecki      p    15  [[255, 251, 253, 255, 233, 73, 139, 166, 116, ...\n",
      "839     grecki      z    16  [[255, 250, 244, 156, 163, 161, 163, 169, 231,...\n",
      "840     grecki      p     1  [[255, 255, 253, 255, 255, 253, 254, 255, 255,...\n",
      "841     grecki      i    25  [[255, 253, 252, 255, 253, 250, 243, 245, 217,...\n",
      "842     grecki      i    11  [[255, 252, 255, 255, 252, 95, 71, 217, 251, 2...\n",
      "843     grecki      i    19  [[254, 252, 255, 253, 252, 255, 181, 255, 255,...\n",
      "844     grecki      i    20  [[255, 253, 255, 252, 254, 255, 253, 254, 255,...\n",
      "845     grecki      o    24  [[250, 255, 254, 255, 252, 255, 255, 255, 254,...\n",
      "846     grecki      o    11  [[254, 255, 250, 255, 255, 82, 53, 46, 45, 57,...\n",
      "847     grecki      p    16  [[255, 253, 250, 255, 248, 253, 255, 202, 253,...\n",
      "848     grecki      i     8  [[251, 255, 252, 255, 253, 253, 139, 172, 252,...\n",
      "849     grecki      o    12  [[251, 253, 255, 218, 252, 87, 37, 16, 29, 29,...\n",
      "850     grecki      z    11  [[250, 242, 250, 202, 229, 231, 244, 243, 241,...\n",
      "851     grecki      p     8  [[254, 248, 243, 228, 214, 159, 54, 32, 20, 26...\n",
      "852     grecki      p     2  [[254, 254, 255, 252, 255, 253, 255, 251, 250,...\n",
      "853     grecki      o     6  [[255, 249, 229, 231, 53, 43, 39, 41, 39, 39, ...\n",
      "854     grecki      z    26  [[254, 255, 99, 100, 83, 73, 62, 137, 143, 219...\n",
      "855     grecki      z     6  [[254, 254, 255, 253, 254, 255, 253, 255, 255,...\n",
      "\n",
      "[856 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(679, 225)\n",
      "0.265095729013\n",
      "[[  0   0   0 171]\n",
      " [  0   0   0 163]\n",
      " [  0   0   0 165]\n",
      " [  0   0   0 180]]\n",
      "(177, 225)\n",
      "0.225988700565\n",
      "[[ 0  0  0 48]\n",
      " [ 0  0  0 36]\n",
      " [ 0  0  0 53]\n",
      " [ 0  0  0 40]]\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(C = 0.5, gamma = 0.2)\n",
    "train = np.random.uniform(0, 1, rows_cnt)\n",
    "indices = np.arange(0, rows_cnt)[train <= 0.8]\n",
    "X = data[\"Image\"][indices].values\n",
    "y = data[\"Letter\"][indices].values\n",
    "X = np.concatenate(X).reshape(X.shape[0], 225)\n",
    "print(X.shape)\n",
    "clf.fit(X, y)\n",
    "print(clf.score(X, y))\n",
    "print(confusion_matrix(y, clf.predict(X)))\n",
    "indices = np.arange(0, rows_cnt)[train > 0.8]\n",
    "X = data[\"Image\"][indices].values\n",
    "y = data[\"Letter\"][indices].values\n",
    "X = np.concatenate(X).reshape(X.shape[0], 225)\n",
    "print(X.shape)\n",
    "print(clf.score(X, y))\n",
    "print(confusion_matrix(y, clf.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-00c43661b499>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdata_pca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_pca\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_pca\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Letter\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/pca.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mitself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \"\"\"\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,\n\u001b[0;32m--> 370\u001b[0;31m                         copy=self.copy)\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;31m# Handle n_components==None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    431\u001b[0m                                       force_all_finite)\n\u001b[1;32m    432\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=10)\n",
    "pca.fit(data[\"Image\"].values)\n",
    "data_pca = pca.transform(data[\"Image\"].values)\n",
    "X = data_pca[indices]\n",
    "y = data[\"Letter\"][indices].values\n",
    "X = np.concatenate(X).reshape(X.shape[0], 225)\n",
    "print(X.shape)\n",
    "clf.fit(X, y)\n",
    "print(clf.score(X, y))\n",
    "print(confusion_matrix(y, clf.predict(X)))\n",
    "indices = np.arange(0, rows_cnt)[train > 0.8]\n",
    "X = data_pca[indices]\n",
    "y = data[\"Letter\"][indices].values\n",
    "X = np.concatenate(X).reshape(X.shape[0], 225)\n",
    "print(X.shape)\n",
    "print(clf.score(X, y))\n",
    "print(confusion_matrix(y, clf.predict(X)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
